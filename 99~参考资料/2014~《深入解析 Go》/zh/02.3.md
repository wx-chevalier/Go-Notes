# 2.3 map 的实现

Go 中的 map 在底层是用哈希表实现的，你可以在 $GOROOT/src/pkg/runtime/hashmap.goc 找到它的实现。

## 数据结构

哈希表的数据结构中一些关键的域如下所示：

    struct Hmap
    {
    	uint8   B;	// 可以容纳2^B个项
    	uint16  bucketsize;   // 每个桶的大小

    	byte    *buckets;     // 2^B个Buckets的数组
    	byte    *oldbuckets;  // 前一个buckets，只有当正在扩容时才不为空
    };

上面给出的结构体只是 Hmap 的部分的域。需要注意到的是，这里直接使用的是 Bucket 的数组，而不是 Bucket\*指针的数组。这意味着，第一个 Bucket 和后面溢出链的 Bucket 分配有些不同。第一个 Bucket 是用的一段连续的内存空间，而后面溢出链的 Bucket 的空间是使用 mallocgc 分配的。

这个 hash 结构使用的是一个可扩展哈希的算法，由 hash 值 mod 当前 hash 表大小决定某一个值属于哪个桶，而 hash 表大小是 2 的指数，即上面结构体中的 2^B。每次扩容，会增大到上次大小的两倍。结构体中有一个 buckets 和一个 oldbuckets 是用来实现增量扩容的。正常情况下直接使用 buckets，而 oldbuckets 为空。如果当前哈希表正在扩容中，则 oldbuckets 不为空，并且 buckets 大小是 oldbuckets 大小的两倍。

具体的 Bucket 结构如下所示：

    struct Bucket
    {
    	uint8  tophash[BUCKETSIZE]; // hash值的高8位....低位从bucket的array定位到bucket
    	Bucket *overflow;           // 溢出桶链表，如果有
    	byte   data[1];             // BUCKETSIZE keys followed by BUCKETSIZE values
    };

其中 BUCKETSIZE 是用宏定义的 8，每个 bucket 中存放最多 8 个 key/value 对, 如果多于 8 个，那么会申请一个新的 bucket，并将它与之前的 bucket 链起来。

按 key 的类型采用相应的 hash 算法得到 key 的 hash 值。将 hash 值的低位当作 Hmap 结构体中 buckets 数组的 index，找到 key 所在的 bucket。将 hash 的高 8 位存储在了 bucket 的 tophash 中。**注意，这里高 8 位不是用来当作 key/value 在 bucket 内部的 offset 的，而是作为一个主键，在查找时对 tophash 数组的每一项进行顺序匹配的**。先比较 hash 值高位与 bucket 的 tophash[i]是否相等，如果相等则再比较 bucket 的第 i 个的 key 与所给的 key 是否相等。如果相等，则返回其对应的 value，反之，在 overflow buckets 中按照上述方法继续寻找。

整个 hash 的存储如下图所示(临时先采用了 XX 同学画的图，这个图有点问题)：

![](https://ngte-superbed.oss-cn-beijing.aliyuncs.com/uPic/images/2.2.map.png?raw=true)

图 2.2 HMap 的存储结构

注意一个细节是 Bucket 中 key/value 的放置顺序，是将 keys 放在一起，values 放在一起，为什么不将 key 和对应的 value 放在一起呢？如果那么做，存储结构将变成 key1/value1/key2/value2… 设想如果是这样的一个 map[int64]int8，考虑到字节对齐，会浪费很多存储空间。不得不说通过上述的一个小细节，可以看出 Go 在设计上的深思熟虑。

## 增量扩容

大家都知道哈希表表就是以空间换时间，访问速度是直接跟填充因子相关的，所以当哈希表太满之后就需要进行扩容。

如果扩容前的哈希表大小为 2^B，扩容之后的大小为 2^(B+1)，每次扩容都变为原来大小的两倍，哈希表大小始终为 2 的指数倍，则有(hash mod 2^B)等价于(hash & (2^B-1))。这样可以简化运算，避免了取余操作。

假设扩容之前容量为 X，扩容之后容量为 Y，对于某个哈希值 hash，一般情况下(hash mod X)不等于(hash mod Y)，所以扩容之后要重新计算每一项在哈希表中的新位置。当 hash 表扩容之后，需要将那些旧的 pair 重新哈希到新的 table 上(源代码中称之为 evacuate)， 这个工作并没有在扩容之后一次性完成，而是逐步的完成（在 insert 和 remove 时每次搬移 1-2 个 pair），Go 语言使用的是增量扩容。

为什么会增量扩容呢？主要是缩短 map 容器的响应时间。假如我们直接将 map 用作某个响应实时性要求非常高的 web 应用存储，如果不采用增量扩容，当 map 里面存储的元素很多之后，扩容时系统就会卡往，导致较长一段时间内无法响应请求。不过增量扩容本质上还是将总的扩容时间分摊到了每一次哈希操作上面。

扩容会建立一个大小是原来 2 倍的新的表，将旧的 bucket 搬到新的表中之后，并不会将旧的 bucket 从 oldbucket 中删除，而是加上一个已删除的标记。

正是由于这个工作是逐渐完成的，这样就会导致一部分数据在 old table 中，一部分在 new table 中， 所以对于 hash table 的 insert, remove, lookup 操作的处理逻辑产生影响。只有当所有的 bucket 都从旧表移到新表之后，才会将 oldbucket 释放掉。

扩容的填充因子是多少呢？如果 grow 的太频繁，会造成空间的利用率很低， 如果很久才 grow，会形成很多的 overflow buckets，查找的效率也会下降。 这个平衡点如何选取呢(在 go 中，这个平衡点是有一个宏控制的(#define LOAD 6.5), 它的意思是这样的，如果 table 中元素的个数大于 table 中能容纳的元素的个数， 那么就触发一次 grow 动作。那么这个 6.5 是怎么得到的呢？原来这个值来源于作者的一个测试程序，遗憾的是没能找到相关的源码，不过作者给出了测试的结果：

            LOAD    %overflow  bytes/entry     hitprobe    missprobe
            4.00         2.13        20.77         3.00         4.00
            4.50         4.05        17.30         3.25         4.50
            5.00         6.85        14.77         3.50         5.00
            5.50        10.55        12.94         3.75         5.50
            6.00        15.27        11.67         4.00         6.00
            6.50        20.90        10.79         4.25         6.50
            7.00        27.14        10.15         4.50         7.00
            7.50        34.03         9.73         4.75         7.50
            8.00        41.10         9.40         5.00         8.00

     %overflow   = percentage of buckets which have an overflow bucket
     bytes/entry = overhead bytes used per key/value pair
     hitprobe    = # of entries to check when looking up a present key
     missprobe   = # of entries to check when looking up an absent key

可以看出作者取了一个相对适中的值。

## 查找过程

1. 根据 key 计算出 hash 值。
2. 如果存在 old table, 首先在 old table 中查找，如果找到的 bucket 已经 evacuated，转到步骤 3。 反之，返回其对应的 value。
3. 在 new table 中查找对应的 value。

这里一个细节需要注意一下。不认真看可能会以为低位用于定位 bucket 在数组的 index，那么高位就是用于 key/valule 在 bucket 内部的 offset。事实上高 8 位不是用作 offset 的，而是用于加快 key 的比较的。

    do { //对每个桶b
    	//依次比较桶内的每一项存放的tophash与所求的hash值高位是否相等
    	for(i = 0, k = b->data, v = k + h->keysize * BUCKETSIZE; i < BUCKETSIZE; i++, k += h->keysize, v += h->valuesize) {
    		if(b->tophash[i] == top) {
    			k2 = IK(h, k);
    			t->key->alg->equal(&eq, t->key->size, key, k2);
    			if(eq) { //相等的情况下再去做key比较...
    				*keyp = k2;
    				return IV(h, v);
    			}
    		}
    	}
    	b = b->overflow; //b设置为它的下一下溢出链
    } while(b != nil);

## 插入过程分析

1. 根据 key 算出 hash 值，进而得出对应的 bucket。
2. 如果 bucket 在 old table 中，将其重新散列到 new table 中。
3. 在 bucket 中，查找空闲的位置，如果已经存在需要插入的 key，更新其对应的 value。
4. 根据 table 中元素的个数，判断是否 grow table。
5. 如果对应的 bucket 已经 full，重新申请新的 bucket 作为 overbucket。
6. 将 key/value pair 插入到 bucket 中。

这里也有几个细节需要注意一下。

在扩容过程中，oldbucket 是被冻结的，查找时会在 oldbucket 中查找，但不会在 oldbucket 中插入数据。如果在 oldbucket 是找到了相应的 key，做法是将它迁移到新 bucket 后加入 evalucated 标记。并且还会额外的迁移另一个 pair。

然后就是只要在某个 bucket 中找到第一个空位，就会将 key/value 插入到这个位置。也就是位置位于 bucket 前面的会覆盖后面的(类似于存储系统设计中做删除时的常用的技巧之一，直接用新数据追加方式写，新版本数据覆盖老版本数据)。找到了相同的 key 或者找到第一个空位就可以结束遍历了。不过这也意味着做删除时必须完全的遍历 bucket 所有溢出链，将所有的相同 key 数据都删除。所以目前 map 的设计是为插入而优化的，删除效率会比插入低一些。

## map 设计中的性能优化

读完 map 源代码发现作者还是做了很多设计上的选择的。本人水平有限，谈不上优劣的点评，这里只是拿出来与读者分享。

HMap 中是 Bucket 的数组，而不是 Bucket 指针的数组。好的方面是可以一次分配较大内存，减少了分配次数，避免多次调用 mallocgc。但相应的缺点，其一是可扩展哈希的算法并没有发生作用，扩容时会造成对整个数组的值拷贝(如果实现上用 Bucket 指针的数组就是指针拷贝了，代价小很多)。其二是首个 bucket 与后面产生了不一致性。这个会使删除逻辑变得复杂一点。比如删除后面的溢出链可以直接删除，而对于首个 bucket，要等到 evalucated 完毕后，整个 oldbucket 删除时进行。

没有重用设 freelist 重用删除的结点。作者把这个加了一个 TODO 的注释，不过想了一下觉得这个做的意义不大。因为一方面，bucket 大小并不一致，重用比较麻烦。另一方面，下层存储已经做过内存池的实现了，所以这里不做重用也会在内存分配那一层被重用的，

bucket 直接 key/value 和间接 key/value 优化。这个优化做得蛮好的。注意看代码会发现，如果 key 或 value 小于 128 字节，则它们的值是直接使用的 bucket 作为存储的。否则 bucket 中存储的是指向实际 key/value 数据的指针，

bucket 存 8 个 key/value 对。查找时进行顺序比较。第一次发现高位居然不是用作 offset，而是用于加快比较的。定位到 bucket 之后，居然是一个顺序比较的查找过程。后面仔细想了想，觉得还行。由于 bucket 只有 8 个，顺序比较下来也不算过分。仍然是 O(1)只不过前面系数大一点点罢了。相当于 hash 到一个小范围之后，在这个小范围内顺序查找。

插入删除的优化。前面已经提过了，插入只要找到相同的 key 或者第一个空位，bucket 中如果存在一个以上的相同 key，前面覆盖后面的(只是如果，实际上不会发生)。而删除就需要遍历完所有 bucket 溢出链了。这样 map 的设计就是为插入优化的。考虑到一般的应用场景，这个应该算是很合理的。

作者还列了另个 2 个 TODO：将多个几乎要 empty 的 bucket 合并；如果 table 中元素很少，考虑 shrink table。(毕竟现在的实现只是单纯的 grow)。

## links

- [目录](preface.md)
- 上一节: [slice](02.2.md)
- 下一节: [nil 的语义](02.4.md)
